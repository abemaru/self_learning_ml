{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "本ノートブックは、kmeans++のアルゴリズムについてなんとなく理解をするためのノートブックです。\n",
    "\n",
    "# Paragraph\n",
    "1. kmeans++の前にkmeansを復習する\n",
    "2. kmeans++って何か\n",
    "3. kmeansとkmeans++の違い、利点を理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. kmeans++の前にkmeansを復習する\n",
    "## 1-1. 階層クラスター分析と非階層クラスター分析\n",
    "クラスター分析には、階層クラスター分析と非階層クラスター分析の2つがあります。\n",
    "\n",
    "### 階層クラスター分析\n",
    "階層クラスター分析は、もっとも似ている組み合わせから順番にまとまり(クラスター)にしていく方法です。  \n",
    "階層クラスター分析の例としては、\n",
    "- ウォード法\n",
    "- 最長距離法\n",
    "- 最短距離法\n",
    "- 群平均法\n",
    "などがあります。(各手法についての説明は省く)\n",
    "\n",
    "階層クラスター分析の利点としては、\n",
    "- 近いものから順番にクラスター分けしていくので、あらかじめクラスター数を決める必要がない\n",
    "- ただ分類するだけでなく、結果として出力される樹形図から、分類の過程でできるクラスターがどのように結合されていくのかを一つ一つ確認できるので、後からクラスター数を決めるのも容易\n",
    "\n",
    "そして、階層クラスター分析の欠点は、\n",
    "- 分類の対象が非常に多くなると、計算量が多くなり実行が困難になる\n",
    "- 分類の対象が多くなると系統図が巨大になり、結果が不明瞭になる\n",
    "\n",
    "上記の欠点から、非常に多くのデータを対象とするクラスター分析では、非階層的クラスター分析を行うのが一般的.\n",
    "\n",
    "### 非階層クラスター分析\n",
    "非階層クラスター分析は、異なる性質のものが混ざり合った集団から、お互いに似た性質を持つものを集めクラスターを作る方法です。  \n",
    "非階層クラスター分析の手法の一つがkmeansです。\n",
    "\n",
    "kmeansは、ビッグデータをクラスターに分けることができますが以下のような欠点があります。\n",
    "- 最適なクラスター数を自動で計算できないので分析者が試行錯誤をしてクラスター数を決定する必要がある\n",
    "- 「初期値依存性」という問題点(後述)\n",
    "\n",
    "ただ、現在ではそれぞれの欠点を埋めるためのアルゴリズムが開発されているみたいです。\n",
    "- クラスター数を決定する必要がある問題　-> `x-means`\n",
    "- 「初期値依存性」 -> `k-means++`\n",
    "\n",
    "## 1-2. kmeansとは\n",
    "kmeansの名称は **「クラスターの平均（means）を用い、あらかじめ決められたクラスター数「k」個に分類する」** に由しています。\n",
    "\n",
    "数式で書くと下記のように最適化問題を解くアルゴリズムとなる。\n",
    "$$\n",
    "    \\mathrm{arg min}_{c_1...c_k}f = \\sum_{i=1}^{n}\\underset{j}{\\mathrm{min}}||x_i-c_j||^{2}\n",
    "$$\n",
    "\n",
    "kmeansは以下のような流れとなっている。データの数を$n$、クラスタの数を$k$とするとき、\n",
    "1. クラスタ数である$k$を決める\n",
    "2. セントロイドとして$k$個の特徴量ベクトルを無作為に決めて、特徴量ベクトル空間に置く\n",
    "3. 各データ$x$と各セントロイド$c$との距離を計算して各データに最も近いセントロイドを割り当てる\n",
    "4. 各セントロイドについてデータの特徴量ベクトルの平均を算出し、これらの平均特徴量ベクトルが新たなセントロイドとなる\n",
    "5. 再び、各データと新たなセントロイドとの距離を計算し、データに対するセントロイドの割り当てを修正し、割り当てに変更がなくなるまで繰り返す\n",
    "\n",
    "## 1-3. 実際にkmeansを実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考文献\n",
    "- web\n",
    "  - [クラスター分析の手法②(階層クラスター分析) -ALBERT](https://www.albert2005.co.jp/knowledge/data_mining/cluster/hierarchical_clustering)  \n",
    "  - [クラスター分析の手法③(非階層クラスター分析) -ALBERT](https://www.albert2005.co.jp/knowledge/data_mining/cluster/non-hierarchical_clustering)\n",
    "- book\n",
    "  - [機械学習100+ページエッセンス -impress top gearシリーズ](https://amzn.to/3nEtLIy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
